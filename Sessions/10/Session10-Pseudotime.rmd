---
title: "SCRGOT 2023 Coder Upgrade Session 10 - Pseudotime analysis and RNA velocity"
author: "Ryan Roberts"
date: "3/4/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(rrrSingleCellUtils)
library(Seurat)
library(slingshot)
library(parallel)

# Required to access the libraries needed for the 'units' package to function
# (Monocle dependency)
system("ml UDUNITS")
library(monocle3)

theme_set(theme_classic())
```

## Import a merged bone tumor object 

This object contains tumor cells isolated from a collection of clinical specimens sequenced using a 3'-capture, microfluidic partitioning approach (10x). The data have already been processed, including isolation/sublustering of tumor cells (other cell types have been filtered out), normalization, scaling, FindNeighbors, FindClusters, etc. The associated metadata contain some potentially useful annotations:
    - $src: a study ID representing the original source (patient) that the tumor was taken from
    - $type: location of the tumor when removed from the patient (Primary or Metastasis)
    - $path: the pathology classification of the tumor (Conventional, Chondroblastic, Telangiectatic, etc.)
    - $gse: the GEO/SRA accession number where the raw data is stored
    - $assignment: the tumor cell subset (cluster) assigment from the previous analysis
    - $partition: a higher-level set of clustering data ("clusters of clusters") that is used by Monocle during the pseudotime determination process.

Start by loading the data and visualizing the appearance/clustering as processed previously.

```{r import_data}
# Load the Seurat object into the namespace as 'scdata'
load("osteoshark.RData")

# Plot the data as it has been processed
r_dim_plot(seurat_obj, "Starting Processed Data")
```

## Practice 1: Basic pseudotime analysis and visualization (monocle3)

Since pseudotime analysis will be performed in Monocle, we must first convert our beloved Seurat object into an object class that Monocle can use.

The following online book provides a nice reference for understanding the SingleCellExperiment object. While Monocle uses a technically different object class called "cell_data_set", this is essentially just a SingleCellExperiment object with some additional slots added to it. All of the functions that can be used with SingleCellExperiment can also be used with cell_data_set.

https://bioconductor.org/books/3.13/OSCA.intro/the-singlecellexperiment-class.html 

To convert a Seurat object to a cell_data_set object, you have a few options. The first extracts specific pieces of data from your seurat object to create three different elements that can then be used to create a new cell_data_set object from scratch. This method give the most flexibility, and I encourage you to try it, but for most purposes, the "as.cell_data_set" function from the SeuratWrappers package will work just fine. It automates the process to extract most of the useful data (and metadata). 

This "as.cell_data_set" function does have a nice feature for transferring the clustering and partitioning data directly into the new object. To take advantage of this feature, you simply need to create two metadata elements within your Seurat object named "monocle3_clusters" and "monocle3_partitions"  that contain the cell-level cluster and partition assignments. If these are present when you run the as.cell_data_set function, they will be automatically recognized and handled without further input.

(For the workflow below, the monocle3 documentation on the Trapnell lab website is a pretty good reference: https://cole-trapnell-lab.github.io/monocle3/docs/trajectories/)

To prepare for pseudotime analysis:
1. Create the monocle3_clusters and monocle3_partitions metadata elements from the existing assignment and partition variables.
2. Create a new cell_data_set object by converting the seurat_obj Seurat object.
3. Explore the cell_data_set object to ensure that appropriate metadata, assays, and dimensional reductions have been included in the conversion. (Hint: make use of the colData, reducedDims, and assayNames functions from the SingleCellExperiment and SummarizedExperiment packages).
4. Plot the UMAP that transferred to the cell_data_set object to ensure that you kept your embeddings. (Hint: Monocle uses a function called plot_cells).
5. Perform the pseudotime analysis using learn_graph from Monocle3.
6. Order the cells by identifying a root node (order_cells function).
7. Plot the pseudotime graph coloring each cell by pseudotime from the chosen root.
8. BONUS. There are many parameters that can be tweaked to optimize the pseudotime analysis. One of the most helpful/commonly adjusted is the ncenter parameter, which adjusts the number of centroids used to compare changes in expression over time. You can think of this as the "resolution" of the assay. Write a loop or an apply-function statement to examine the effects of different values for ncenter on the resulting graph. (HINT: Use values in the range of 50-2000. This is also a great problem to leverage your skills in parallel processing. For a bonus-bonus, benchmark the time savings you get from parallel processing.)
9. BONUS. Compete for the most beautiful pseudotime visual: upload your best plot of the pseudotime graph to the "***" folder on the CoderUpgrade OneDrive.
10. BONUS. See how results compare if you let monocle3 perform the clustering and processing. Do you get similar results?

```{r enrollment}
# Add metadata to carry over the clustering information to the new object
seurat_obj$monocle3_clusters <- seurat_obj$assignment
seurat_obj$monocle3_partitions <- "p1"

# Convert the Seurat object to a Monocle (cell_data_set) object
cds_obj <- SeuratWrappers::as.cell_data_set(seurat_obj)

# View the transferred metadata, dimensional reductions, and assays
as_tibble(colData(cds_obj))
reducedDims(cds_obj)
assayNames(cds_obj)

# Calculate the pseudotime/trajectories, then
# Test different parameters for ncenter ("resolution" of the trajectory graph)
g <- list()
g <- parallel::mclapply(c(200, 300, 400, 500), function(s) {
    p <- cluster_cells(cds_obj) %>%
        learn_graph(use_partition = FALSE,
        learn_graph_control = list(ncenter = s)) %>%
        plot_cells(graph_label_size = 5) +
        ggtitle(paste("ncenter =", s)) +
        coord_fixed()
    return(p)
}, mc.cores = 4)
(g[[1]] | g[[2]]) / (g[[3]] | g[[4]])

# Choose ncenter = 300 -- it picks up the inflammatory cluster as a leaf
cds_obj <- cluster_cells(cds_obj) %>%
    learn_graph(use_partition = FALSE,
    learn_graph_control = list(ncenter = 300))

# Plot cells colored by pesudotime (have to order first [interactive])
cds_obj <- order_cells(cds_obj,
    reduction_method = "UMAP")
plot_cells(cds_obj,
    color_cells_by = "pseudotime",
    cell_size = 0.75,
    graph_label_size = 5,
    trajectory_graph_segment_size = 1.5) +
    ggtitle("Osteoshark connected with pseudotime") +
    coord_fixed()

# Do it with Monocle-generated processing
cds_obj <- cds_obj %>%
    preprocess_cds(num_dim = 30) %>%
    align_cds(alignment_group = "src") %>%
    reduce_dimension() %>%
    cluster_cells() %>%
    learn_graph(use_partition = FALSE)
plot_cells(cds_obj,
    color_cells_by = "assignment")
```

## Practice 2: Identify genes associated with branch-to-leaf transitions

Now, perform a differential expression analysis with your favorite trajectory to identify genes that vary at the branch pointes and that define the leaves across pseudotime. This is called a "graph autocorrelation analysis" in the world of Monocle.

1. Using a cell_data_set object generated above, find genes whose expression differentiates branches and leaves from each other (use graph_test from monocle3). Be sure to specify "neighbor_graph" as "principal_graph", or it will default to the knn method, which will give you degs between clusters (the default behavior).
2. Explore the resulting data frame. This shows how each gene within your object vary across the trajectory while being similar within spatially-nearby cells (Moran's I).
3. 
2. Pick a leaf or two of interest.
3. Explore the genes that distinguish those leaves from each other. Pick 2-4 genes of interest. Find at least one gene whose expression is lost over the trajectory.
4. Plot those genes of interest visually on the UMAP to show how expression changes over time. 


```{r}
# Create a data frame containing genes that differentiate branches and leaves
# from each other
pseudo_degs <- graph_test(cds_obj,
    neighbor_graph = "principal_graph",
    cores = 4)
head(pseudo_degs, n = 20)
head(pseudo_degs %>% arrange(-morans_I), n = 20)

# Fix the rownames created in the conversion process by seuratWrappers
rowData(cds_obj)$gene_name <- rownames(cds_obj)
rowData(cds_obj)$gene_short_name <- rowData(cds_obj)$gene_name

# Plot a few selected genes from the DEG onto the trajectory
plot_genes <- pseudo_degs %>%
    arrange(-morans_I) %>%
    head(n = 16) %>%
    rownames()

p <- plot_cells(cds_obj,
    genes = plot_genes,
    cell_size = 1,
    cell_stroke = 0,
    label_branch_points = FALSE,
    label_leaves = FALSE,
    trajectory_graph_segment_size = 0.75)

# Select genes of interest from the graph_test and perform reverse
# UMAP embedding/clustering *** in progress
genes_of_interest <- pseudo_degs %>%
    filter(q_value < 0.05) %>%
    filter(morans_I > 0.1) %>%
    rownames()
cds_subset <- tibble(cell = rownames(colData(cds_obj)),
    cell_group = colData(cds_obj)$cell.type)
expression_modules <- find_gene_modules(
    cds_obj[genes_of_interest, ],
    resolution = c(10^seq(-6, -1)))
```

## Practice 3: Trajectory analysis with slingshot

***

A helpful reference to understand the workflow is the vignette included with the slingshot package in the bioconductor repository: https://bioconductor.org/packages/devel/bioc/vignettes/slingshot/inst/doc/vignette.html.

```{r rosters, results='asis'}
# Create a singleCellExperiment object from the Seurat object
sce_obj <- as.SingleCellExperiment(seurat_obj)

# Use this data object to perform trajectory analysis using the
# slingshot algorithm
sce_obj <- slingshot(sce_obj,
    clusterLabels = "assignment",
    reducedDim = "UMAP",
    start.clus = "Growth - ribogenesis")

# Plot the initial trajectory
plot(reducedDims(sce_obj)$UMAP,
    col = plot_cols[colData(sce_obj)$ident],
    asp = 1,
    pch = 16)
lines(SlingshotDataSet(sce_obj), lwd = 2, col = "gray40")

# Plot using ggplot
# Extract relevant data into data frames first
sce_df <- data.frame(reducedDims(sce_obj)$UMAP,
    ident = colData(sce_obj)$ident)

# Plot the minimum spanning tree generated by slingshot
sce_mst <- slingMST(sce_obj, as.df = TRUE)
ggplot(sce_df, aes(x = UMAP_1, y = UMAP_2)) +
    geom_point(aes(color = ident)) +
    geom_point(data = sce_mst,
        size = 3,
        color = "gray40") +
    geom_path(data = sce_mst %>% arrange(Order),
        aes(group = Lineage),
        size = 1.5,
        color = "gray40") +
    scale_color_manual(values = plot_cols) +
    coord_fixed()

# Plot the slingshot-generated trajectories
sce_curves <- slingCurves(sce_obj, as.df = TRUE)
ggplot(sce_df, aes(x = UMAP_1, y = UMAP_2)) +
    geom_point(aes(color = ident)) +
    geom_path(data = sce_curves,
        aes(group = Lineage),
        size = 2,
        color = "gray40") +
    scale_color_manual(values = plot_cols) +
    coord_fixed()
```

## Discussion of pseudotime analysis/trajectory inference

This project gives a brief introduction to the world of pseudotime and trajectory methodologies. The large number of tools that have been developed to address this problem highlights the fact that this is a challenge with an array of imperfect solutions. Each approach provides solutions that address at least one type of problem, while no solution works well for every problem. Finding "true" trajectories often requires some trial and error using multiple different algorithms, which can often be complimentary.

A very nice comparative evaluation of the different approaches to pseudotime/trajectory analysis has been published by Saelens et al (https://doi.org/10.1038/s41587-019-0071-9). It really is worth a read if you want to understand more. You might also check out the metapackage the authors built to support their comparative benchmarking (https://github.com/dynverse/dyno). It's a little outdated at this point, but they did a good job putting it together.

Once weakness in nearly all of these approaches is that trajectories are almost entirely inferential. They should be viewed as different ways to "connect the dots," but they are NOT clear evidence that one cell type/cluster gives rise to another. Moreover, while some algorithms will generate educated guesses as to the directionality in the different connections between clusters, inferences of origin and destination are really just guesses. 

One can often use techniques such as RNA Velocity Analysis to get more direct evidence for directionality and evolutionary relationships. Indeed, these two techniques should be viewed as being highly complimentary. We will not have time to dive into velocity analysis today (maybe next year), but the following resources are a good place to start if you'd like to learn more:
 - https://doi.org/10.1371/journal.pcbi.1010492
 - https://doi.org/10.15252/msb.202110282
 - https://scvelo.readthedocs.io/en/stable/


## Session challenge

To take on today's challenge, install the dyno package* and then use it to compare results of several different approaches to trajectory inference using the same object(s). The data could be the same dataset used in class today, one taken from a repository, or one of your own. To qualify for judging, you must generate at least 8 distinct plots/analyses that evaluate different trajectories or gene expression modules that vary with pseudotime. Winners will be selected based on the following principles:
 - how appropriate the analyses are for addressing the problem/question
 - how creative the approach is
 - how well the approach is documented
 - how beautifully/accessibly the results are presented

To submit your code for judging, just save a new file titled "Session10-Challenge-Ryan_Roberts.Rmd" (replacing my name with yours, obviously) in the "Challenges" folder on the SCRGOT Coder Upgrade OneDrive.

*NOTE: Running the dyno package requires singularity. Singularity joined forces with the Linux foundation and became Apptainer, which is already installed on the Franklin cluster. When you run singularity commands, these will be automatically run by apptainer, and it works fine. However, if you run test_singularity_installation and use the "detailed = TRUE" option, it will tell you that the version is old. Just ignore this. Any apptainer installation is equivalent to a singularity version >3.8.

```{r}
system("ml load GCCcore/9.3.0 ImageMagick")
library(dyno)

# Set up the dyno object from the Seurat data
# First, add the raw and normalized counts
dyn_obj <- wrap_expression(
    expression = GetAssayData(seurat_obj, slot = "data", assay = "RNA") %>% t(),
    counts = GetAssayData(seurat_obj, slot = "counts", assay = "RNA") %>% t())

# Second, add the clustering information
dyn_obj <- add_grouping(dyn_obj, seurat_obj$assignment)
 
# And the UMAP embeddings
dyn_obj <- add_dimred(dyn_obj, Embeddings(seurat_obj[["umap"]]))

# And the starting cell
# Interactive steps run previously:
# CellSelector(DimPlot(seurat_obj))
dyn_obj <- add_prior_information(dyn_obj, 
    start_id = "OS_3_GTTGAACTCTATCGTT-1")

# Use the interactive shiny tool to explore the different methods and choose optimal
picked <- guidelines_shiny(dyn_obj)

# Run the trajectory inferrence algorithms

```